{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data preprocessing...\n",
      "Training LGBM model...\n",
      "[5]\ttraining's auc: 0.695636\n",
      "[10]\ttraining's auc: 0.71049\n",
      "[15]\ttraining's auc: 0.7176\n",
      "[20]\ttraining's auc: 0.722873\n",
      "[25]\ttraining's auc: 0.726978\n",
      "[30]\ttraining's auc: 0.730433\n",
      "[35]\ttraining's auc: 0.733264\n",
      "[40]\ttraining's auc: 0.735801\n",
      "[45]\ttraining's auc: 0.737898\n",
      "[50]\ttraining's auc: 0.739522\n",
      "[55]\ttraining's auc: 0.740636\n",
      "[60]\ttraining's auc: 0.7424\n",
      "[65]\ttraining's auc: 0.743485\n",
      "[70]\ttraining's auc: 0.744442\n",
      "[75]\ttraining's auc: 0.745609\n",
      "[80]\ttraining's auc: 0.746808\n",
      "[85]\ttraining's auc: 0.747932\n",
      "[90]\ttraining's auc: 0.749114\n",
      "[95]\ttraining's auc: 0.750269\n",
      "[100]\ttraining's auc: 0.75177\n",
      "[105]\ttraining's auc: 0.752671\n",
      "[110]\ttraining's auc: 0.754021\n",
      "[115]\ttraining's auc: 0.754611\n",
      "[120]\ttraining's auc: 0.755571\n",
      "[125]\ttraining's auc: 0.7563\n",
      "[130]\ttraining's auc: 0.757008\n",
      "[135]\ttraining's auc: 0.757725\n",
      "[140]\ttraining's auc: 0.758469\n",
      "[145]\ttraining's auc: 0.759108\n",
      "[150]\ttraining's auc: 0.759756\n",
      "[155]\ttraining's auc: 0.760413\n",
      "[160]\ttraining's auc: 0.761255\n",
      "[165]\ttraining's auc: 0.762056\n",
      "[170]\ttraining's auc: 0.762893\n",
      "[175]\ttraining's auc: 0.763498\n",
      "[180]\ttraining's auc: 0.764132\n",
      "[185]\ttraining's auc: 0.764705\n",
      "[190]\ttraining's auc: 0.765313\n",
      "[195]\ttraining's auc: 0.765917\n",
      "[200]\ttraining's auc: 0.766551\n",
      "Making predictions and saving them...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#引用\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "print('Loading data...')\n",
    "data_path = './data/'\n",
    "train = pd.read_csv(data_path + 'train.csv', dtype={'msno' : 'category',\n",
    "                                                'source_system_tab' : 'category',\n",
    "                                                  'source_screen_name' : 'category',\n",
    "                                                  'source_type' : 'category',\n",
    "                                                  'target' : np.uint8,\n",
    "                                                  'song_id' : 'category'})\n",
    "test = pd.read_csv(data_path + 'test.csv', dtype={'msno' : 'category',\n",
    "                                                'source_system_tab' : 'category',\n",
    "                                                'source_screen_name' : 'category',\n",
    "                                                'source_type' : 'category',\n",
    "                                                'song_id' : 'category'})\n",
    "songs = pd.read_csv(data_path + 'songs.csv',dtype={'genre_ids': 'category',\n",
    "                                                  'language' : 'category',\n",
    "                                                  'artist_name' : 'category',\n",
    "                                                  'composer' : 'category',\n",
    "                                                  'lyricist' : 'category',\n",
    "                                                  'song_id' : 'category'})\n",
    "members = pd.read_csv(data_path + 'members.csv',dtype={'city' : 'category',\n",
    "                                                      'bd' : np.uint8,\n",
    "                                                      'gender' : 'category',\n",
    "                                                      'registered_via' : 'category'})\n",
    "songs_extra = pd.read_csv(data_path + 'song_extra_info.csv')\n",
    "\n",
    "#預處理\n",
    "print('Data preprocessing...')\n",
    "song_cols = ['song_id', 'artist_name', 'genre_ids', 'song_length', 'language']\n",
    "train = train.merge(songs[song_cols], on='song_id', how='left')\n",
    "test = test.merge(songs[song_cols], on='song_id', how='left')\n",
    "\n",
    "members['registration_year'] = members['registration_init_time'].apply(lambda x: int(str(x)[0:4]))\n",
    "members['registration_month'] = members['registration_init_time'].apply(lambda x: int(str(x)[4:6]))\n",
    "members['registration_date'] = members['registration_init_time'].apply(lambda x: int(str(x)[6:8]))\n",
    "\n",
    "members['expiration_year'] = members['expiration_date'].apply(lambda x: int(str(x)[0:4]))\n",
    "members['expiration_month'] = members['expiration_date'].apply(lambda x: int(str(x)[4:6]))\n",
    "members['expiration_date'] = members['expiration_date'].apply(lambda x: int(str(x)[6:8]))\n",
    "members = members.drop(['registration_init_time'], axis=1)\n",
    "\n",
    "#計算歌曲年份\n",
    "def isrc_to_year(isrc):\n",
    "    if type(isrc) == str:\n",
    "        if int(isrc[5:7]) > 17:\n",
    "            return 1900 + int(isrc[5:7])\n",
    "        else:\n",
    "            return 2000 + int(isrc[5:7])\n",
    "    else:\n",
    "        return np.nan\n",
    "        \n",
    "songs_extra['song_year'] = songs_extra['isrc'].apply(isrc_to_year)\n",
    "songs_extra.drop(['isrc', 'name'], axis = 1, inplace = True)\n",
    "\n",
    "train = train.merge(members, on='msno', how='left')\n",
    "test = test.merge(members, on='msno', how='left')\n",
    "\n",
    "train = train.merge(songs_extra, on = 'song_id', how = 'left')\n",
    "test = test.merge(songs_extra, on = 'song_id', how = 'left')\n",
    "\n",
    "#Garbage collection 還不清楚\n",
    "import gc\n",
    "del members, songs; gc.collect();\n",
    "\n",
    "for col in train.columns:\n",
    "    if train[col].dtype == object:\n",
    "        train[col] = train[col].astype('category')\n",
    "        test[col] = test[col].astype('category')\n",
    "\n",
    "X = train.drop(['target'], axis=1)\n",
    "y = train['target'].values\n",
    "\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "ids = test['id'].values\n",
    "\n",
    "del train, test; gc.collect();\n",
    "\n",
    "d_train = lgb.Dataset(X, y)\n",
    "watchlist = [d_train]\n",
    "\n",
    "#模型參數 可以自己調一下\n",
    "#light gbm基於決策樹\n",
    "print('Training LGBM model...')\n",
    "params = {}\n",
    "params['learning_rates']=0.2\n",
    "params['application'] = 'binary'\n",
    "params['max_depth'] = 8          #最多長幾層 太深容易overfitting\n",
    "params['num_leaves'] = 2**8      #樹的葉子數量\n",
    "params['verbosity'] = 0\n",
    "params['metric'] = 'auc'\n",
    "\n",
    "model = lgb.train(params, train_set=d_train, num_boost_round=200, valid_sets=watchlist, verbose_eval=5)\n",
    "\n",
    "#預測\n",
    "print('Making predictions and saving them...')\n",
    "p_test = model.predict(X_test)\n",
    "\n",
    "#輸出\n",
    "subm = pd.DataFrame()\n",
    "subm['id'] = ids\n",
    "subm['target'] = p_test\n",
    "subm.to_csv('submission.csv.gz', compression = 'gzip', index=False, float_format = '%.5f')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
